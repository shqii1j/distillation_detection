# distillation_detection
[NeurIPS 2025] Knowledge Distillation Detection for Open-weights Models
### [Project Page] | [Paper](https://arxiv.org/abs/2510.02302)

**[Qin Shi<sup>1*](https://shqii1j.github.io/), [Amber Yijia Zheng<sup>2*](https://amberyzheng.com/)*, [Qifan Song<sup>1](https://www.stat.purdue.edu/~qfsong/), [Raymond A. Yeh<sup>2](https://raymond-yeh.com/)**

<sup>1</sup>Department of Statistics, Purdue University, <sup>2</sup>Department of Computer Science, Purdue University

In NeurIPS 2025.

## Summary
We propose the task of **knowledge distillation detection**, introducing a model-agnostic method that uses data-free input synthesis plus a statistical score, and it works for both classification and text-to-image models.

## TODO
- ()  Installation instruction
- (☑️) Text-to-image code release
- () Image-classification release
- () Usage instruction